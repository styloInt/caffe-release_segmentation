# my AlexNet converted to FCN (pretrained on VOC 21 classes) 


name: "my_alexnet_fcn"

layers {
  name: "data"
  type: IMAGE_SEG_DATA
  top: "data"
  top: "label"
  image_data_param {
    root_folder: "/home/luffy/Documents/Stage/dataSet_preprocess/Train_augmented/"
    source: "/home/luffy/Documents/Stage/dataSet_preprocess/Train_augmented/train_files.txt"
    label_type: PIXEL
    batch_size: 1
    shuffle: true
    new_width: 216
    new_height: 256
  }
  include: { phase: TRAIN }
}

layers {
  name: "data"
  type: IMAGE_SEG_DATA
  top: "data"
  top: "label"
  image_data_param {
    root_folder: "/home/luffy/Documents/Stage/dataSet_preprocess/Test/"
    source: "/home/luffy/Documents/Stage/dataSet_preprocess/Test/test_files.txt"
    label_type: PIXEL
    batch_size: 1
    shuffle: true
    new_width: 216
    new_height: 256
  }
  include: { phase: TEST }
}


## network starts

layers {  bottom: "data"  top: "conv1"  name: "conv1"  type: CONVOLUTION   
  blobs_lr: 1 blobs_lr: 2 weight_decay: 1 weight_decay:0  
  convolution_param {   num_output: 96    pad: 100    kernel_size: 11  stride:4  
  # weight_filler {type: "gaussian" std: 0.01}  bias_filler {type: "constant" value: 0} 
  weight_filler {type: "xavier"} bias_filler {type: "constant"  value: 0} 
  } 
}

layers {  bottom: "conv1"  top: "conv1"  name: "relu1"  type: RELU }

layers {  bottom: "conv1"  top: "pool1"  name: "pool1"  type: POOLING   
  pooling_param {    pool: MAX    kernel_size: 3    stride: 2  }
}

layers { bottom: "pool1"  top: "norm1"  name: "norm1"  type: LRN
  lrn_param {local_size: 5   alpha: 0.0001    beta: 0.75}
}

##
layers {  bottom: "norm1"  top: "conv2"  name: "conv2"  type: CONVOLUTION   
  blobs_lr: 1 blobs_lr: 2 weight_decay: 1 weight_decay:0  
  convolution_param {   num_output: 256    pad: 2    kernel_size: 5   group:2    
  # weight_filler {type: "gaussian" std: 0.01}  bias_filler {type: "constant" value: 1}
  weight_filler {type: "xavier"} bias_filler {type: "constant"  value: 1} 
   } 
}

layers {  bottom: "conv2"  top: "conv2"  name: "relu2"  type: RELU }

layers {  bottom: "conv2"  top: "pool2"  name: "pool2"  type: POOLING   
  pooling_param {    pool: MAX    kernel_size: 3    stride: 2  }
}

layers { bottom: "pool2"  top: "norm2"  name: "norm2"  type: LRN
  lrn_param {local_size: 5   alpha: 0.0001    beta: 0.75}
}

##
layers {  bottom: "norm2"  top: "conv3"  name: "conv3"  type: CONVOLUTION   
  blobs_lr: 1 blobs_lr: 2 weight_decay: 1 weight_decay:0  
  convolution_param {   num_output: 384    pad: 2    kernel_size: 3  
  # weight_filler {type: "gaussian" std: 0.01}  bias_filler {type: "constant" value: 0} 
  weight_filler {type: "xavier"} bias_filler {type: "constant"  value: 0} 
  } 
}

layers {  bottom: "conv3"  top: "conv3"  name: "relu3"  type: RELU }

##
layers {  bottom: "conv3"  top: "conv4"  name: "conv4"  type: CONVOLUTION   
  blobs_lr: 1 blobs_lr: 2 weight_decay: 1 weight_decay:0  
  convolution_param {   num_output: 384    pad: 1    kernel_size: 3  group: 2
  # weight_filler {type: "gaussian" std: 0.01}  bias_filler {type: "constant" value: 1}
  weight_filler {type: "xavier"} bias_filler {type: "constant"  value: 1} 
   } 
}

layers {  bottom: "conv4"  top: "conv4"  name: "relu4"  type: RELU }

##
layers {  bottom: "conv4"  top: "conv5"  name: "conv5"  type: CONVOLUTION   
  blobs_lr: 1 blobs_lr: 2 weight_decay: 1 weight_decay:0  
  convolution_param {   num_output: 256    pad: 1    kernel_size: 3  group: 2
  # weight_filler {type: "gaussian" std: 0.01}  bias_filler {type: "constant" value: 1}
  weight_filler {type: "xavier"} bias_filler {type: "constant"  value: 1} 
   } 
}

layers {  bottom: "conv5"  top: "conv5"  name: "relu5"  type: RELU }


layers {  bottom: "conv5"  top: "pool5"  name: "pool5"  type: POOLING   
  pooling_param {    pool: MAX    kernel_size: 3    stride: 2  }
}

##
layers {  bottom: "pool5"  top: "fc6"  name: "fc6"  type: CONVOLUTION   
  blobs_lr: 1 blobs_lr: 2 weight_decay: 1 weight_decay:0  
  convolution_param {   num_output: 4096    kernel_size: 6  
  # weight_filler {type: "gaussian" std: 0.005}  bias_filler {type: "constant" value: 1}
  weight_filler {type: "xavier"} bias_filler {type: "constant"  value: 1} 
   }  
}

layers {  bottom: "fc6"  top: "fc6"  name: "relu6"  type: RELU }

layers {  bottom: "fc6"  top: "fc6"  name: "drop6"  type: DROPOUT
  dropout_param { dropout_ratio: 0.5} 
}

##
layers {  bottom: "fc6"  top: "fc7"  name: "fc7"  type: CONVOLUTION 
  blobs_lr: 1 blobs_lr: 2 weight_decay: 1 weight_decay:0  
  convolution_param {   num_output: 4096    kernel_size: 1  
  # weight_filler {type: "gaussian" std: 0.005}  bias_filler {type: "constant" value: 1}
  weight_filler {type: "xavier"} bias_filler {type: "constant"  value: 1} 
   }  

}
layers {  bottom: "fc7"  top: "fc7"  name: "relu7"  type: RELU }

layers {  bottom: "fc7"  top: "fc7"  name: "drop7"  type: DROPOUT
  dropout_param { dropout_ratio: 0.5} 
}

##
layers {  bottom: "fc7"  top: "score"  name: "score"  type: CONVOLUTION 
  blobs_lr: 1 blobs_lr: 2 weight_decay: 1 weight_decay:0    
  convolution_param {   num_output: 3    kernel_size: 1  
        # weight_filler {type: "gaussian"  std: 0.005}  bias_filler {type: "constant"  value: 1} 
        weight_filler {type: "xavier"} bias_filler {type: "constant"  value: 1} 
        } 
}

##
layers {  bottom: "score"  top: "score-big"  name: "upsample-big"  type: DECONVOLUTION 
  blobs_lr: 0 blobs_lr: 0 
  convolution_param {   num_output: 3  kernel_size: 63  group: 3 stride: 32  engine: CAFFE weight_filler { type: "bilinear"} }  
        #convolution_param {   num_output: 3  kernel_size: 63  group: 3 stride: 32  engine: CAFFE}
}

layers { bottom: "score-big"  bottom: "data"  top: "score-final"  name: "crop"  type: CROP}

layers {
  name: "seg-accuracy"
  #type: ELTWISE_ACCURACY
  type: TOPO_ACCURACY
  bottom: "score-final"
  bottom: "label"
  top: "seg-accuracy"
  eltwise_accuracy_param {
    ignore_label: 255
  }
  include: { phase: TEST }
}

layers {
    name: "prob_final"    
    type: SOFTMAX_LOSS
    bottom: "score-final"
    bottom: "label"
    top: "loss"
    loss_weight: 0.5
    loss_param {
      # ignore_label: 255
      normalize: true
    }
  }

# layers {
#     name: "prob_topo"    
#     type: TOPO2_LOSS
#     bottom: "score-final"
#     bottom: "label"
#     top: "loss"
#     loss_weight: 0.5
#     loss_param {
#       ignore_label: 255
#       normalize: true
#     }
#   }

  layers {
    name: "prob_final"    
    type: SMOOTH_ONLY_LOSS
    bottom: "score-final"
    bottom: "label"
    top: "loss2"
    loss_weight: 0.5
    loss_param {
      ignore_label: 255
      normalize: true
    }
  }

#layers {
 #  name: "prob"  
 # type: TOPO2_LOSS
 # bottom: "score-final"
 # bottom: "label"
 # top: "loss"
 # loss_param {
 #   ignore_label: 255
 #   normalize: true
 # }
#}
